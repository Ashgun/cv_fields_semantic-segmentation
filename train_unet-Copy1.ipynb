{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, UpSampling2D, Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import params\n",
    "import dataset\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def BuildModel_SegNet():\n",
    "    inp = Input(shape=(params.GetImageSize(), params.GetImageSize(), params.GetChannelsNum()))\n",
    "\n",
    "    conv_1_1 = Conv2D(32, (3, 3), padding='same')(inp)\n",
    "    conv_1_1 = Activation('relu')(conv_1_1)\n",
    "    conv_1_2 = Conv2D(32, (3, 3), padding='same')(conv_1_1)\n",
    "    conv_1_2 = Activation('relu')(conv_1_2)\n",
    "    pool_1 = MaxPooling2D(2)(conv_1_2)\n",
    "\n",
    "    conv_2_1 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "    conv_2_1 = Activation('relu')(conv_2_1)\n",
    "    conv_2_2 = Conv2D(64, (3, 3), padding='same')(conv_2_1)\n",
    "    conv_2_2 = Activation('relu')(conv_2_2)\n",
    "    pool_2 = MaxPooling2D(2)(conv_2_2)\n",
    "\n",
    "    conv_3_1 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "    conv_3_1 = Activation('relu')(conv_3_1)\n",
    "    conv_3_2 = Conv2D(128, (3, 3), padding='same')(conv_3_1)\n",
    "    conv_3_2 = Activation('relu')(conv_3_2)\n",
    "    pool_3 = MaxPooling2D(2)(conv_3_2)\n",
    "\n",
    "    up_1 = UpSampling2D(2, interpolation='bilinear')(pool_3)\n",
    "    conv_up_1_1 = Conv2D(256, (3, 3), padding='same')(up_1)\n",
    "    conv_up_1_1 = Activation('relu')(conv_up_1_1)\n",
    "    conv_up_1_2 = Conv2D(256, (3, 3), padding='same')(conv_up_1_1)\n",
    "    conv_up_1_2 = Activation('relu')(conv_up_1_2)\n",
    "\n",
    "    up_2 = UpSampling2D(2, interpolation='bilinear')(conv_up_1_2)\n",
    "    conv_up_2_1 = Conv2D(128, (3, 3), padding='same')(up_2)\n",
    "    conv_up_2_1 = Activation('relu')(conv_up_2_1)\n",
    "    conv_up_2_2 = Conv2D(128, (3, 3), padding='same')(conv_up_2_1)\n",
    "    conv_up_2_2 = Activation('relu')(conv_up_2_2)\n",
    "\n",
    "    up_3 = UpSampling2D(2, interpolation='bilinear')(conv_up_2_2)\n",
    "    conv_up_3_1 = Conv2D(64, (3, 3), padding='same')(up_3)\n",
    "    conv_up_3_1 = Activation('relu')(conv_up_3_1)\n",
    "    conv_up_3_2 = Conv2D(4, (3, 3), padding='same')(conv_up_3_1)\n",
    "    result = Activation('sigmoid')(conv_up_3_2)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=result)\n",
    "\n",
    "best_w = keras.callbacks.ModelCheckpoint('segnet_best.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=False,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "last_w = keras.callbacks.ModelCheckpoint('segnet_last.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=False,\n",
    "                                save_weights_only=False,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "\n",
    "callbacks = [best_w, last_w]\n",
    "\n",
    "\n",
    "model = BuildModel_SegNet()\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(adam, 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8866642  0.1989913  0.91869265 0.99565184]\n"
     ]
    }
   ],
   "source": [
    "def BuildModel_UNet():\n",
    "    inp = Input(shape=(params.GetImageSize(), params.GetImageSize(), params.GetChannelsNum()))\n",
    "\n",
    "    conv_1_1 = Conv2D(32, (3, 3), padding='same')(inp)\n",
    "    conv_1_1 = Activation('relu')(conv_1_1)\n",
    "    conv_1_2 = Conv2D(32, (3, 3), padding='same')(conv_1_1)\n",
    "    conv_1_2 = Activation('relu')(conv_1_2)\n",
    "    pool_1 = MaxPooling2D(2)(conv_1_2)\n",
    "\n",
    "    conv_2_1 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "    conv_2_1 = Activation('relu')(conv_2_1)\n",
    "    conv_2_2 = Conv2D(64, (3, 3), padding='same')(conv_2_1)\n",
    "    conv_2_2 = Activation('relu')(conv_2_2)\n",
    "    pool_2 = MaxPooling2D(2)(conv_2_2)\n",
    "\n",
    "    conv_3_1 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "    conv_3_1 = Activation('relu')(conv_3_1)\n",
    "    conv_3_2 = Conv2D(128, (3, 3), padding='same')(conv_3_1)\n",
    "    conv_3_2 = Activation('relu')(conv_3_2)\n",
    "    pool_3 = MaxPooling2D(2)(conv_3_2)\n",
    "\n",
    "    up_1 = UpSampling2D(2, interpolation='bilinear')(pool_3)\n",
    "    conc_1 = Concatenate()([conv_3_2, up_1])\n",
    "    conv_up_1_1 = Conv2D(256, (3, 3), padding='same')(conc_1)\n",
    "    conv_up_1_1 = Activation('relu')(conv_up_1_1)\n",
    "    conv_up_1_2 = Conv2D(256, (3, 3), padding='same')(conv_up_1_1)\n",
    "    conv_up_1_2 = Activation('relu')(conv_up_1_2)\n",
    "\n",
    "    up_2 = UpSampling2D(2, interpolation='bilinear')(conv_up_1_2)\n",
    "    conc_2 = Concatenate()([conv_2_2, up_2])\n",
    "    conv_up_2_1 = Conv2D(128, (3, 3), padding='same')(conc_2)\n",
    "    conv_up_2_1 = Activation('relu')(conv_up_2_1)\n",
    "    conv_up_2_2 = Conv2D(128, (3, 3), padding='same')(conv_up_2_1)\n",
    "    conv_up_2_2 = Activation('relu')(conv_up_2_2)\n",
    "\n",
    "    up_3 = UpSampling2D(2, interpolation='bilinear')(conv_up_2_2)\n",
    "    conc_3 = Concatenate()([conv_1_2, up_3])\n",
    "    conv_up_3_1 = Conv2D(64, (3, 3), padding='same')(conc_3)\n",
    "    conv_up_3_1 = Activation('relu')(conv_up_3_1)\n",
    "    conv_up_3_2 = Conv2D(4, (3, 3), padding='same')(conv_up_3_1)\n",
    "    result = Activation('sigmoid')(conv_up_3_2)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=result)\n",
    "\n",
    "best_w = keras.callbacks.ModelCheckpoint('unet_best.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=False,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "last_w = keras.callbacks.ModelCheckpoint('unet_last.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=False,\n",
    "                                save_weights_only=False,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "\n",
    "callbacks = [best_w, last_w]\n",
    "\n",
    "\n",
    "model = BuildModel_UNet()\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "weights = np.array([11.333580017089844, 80.10086822509766, 8.1307373046875, 0.434814453125]).astype(np.float32) / 100.0\n",
    "weights = (np.sum(weights) - weights / np.sum(weights))\n",
    "print(weights)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    metrics=['accuracy'], \n",
    "    loss=weighted_categorical_crossentropy(weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete reading input data. Will Now print a snippet of it\n",
      "Number of files in Training-set:\t\t1000\n",
      "Number of files in Validation-set:\t200\n"
     ]
    }
   ],
   "source": [
    "data = dataset.read_train_validation_big_sets(\n",
    "        train_path = os.path.join(params.training_data_path),\n",
    "        validation_path = os.path.join(params.validation_data_path),\n",
    "        image_size = params.GetImageSize())\n",
    "\n",
    "print(\"Complete reading input data. Will Now print a snippet of it\")\n",
    "print(\"Number of files in Training-set:\\t\\t{}\".format(data.train.num_examples))\n",
    "print(\"Number of files in Validation-set:\\t{}\".format(data.valid.num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_df = data.train.image_paths\n",
    "mask_df = data.train.masks_paths\n",
    "batch_size = 26\n",
    "\n",
    "index = 0\n",
    "while index < 5:\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    r_batch = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img_name = img_df[index]\n",
    "        mask_name = mask_df[index]\n",
    "\n",
    "#             print(index, img_name, mask_name)\n",
    "\n",
    "        index = (index + 1) % len(img_df)\n",
    "\n",
    "        img = cv2.imread(img_name, cv2.IMREAD_COLOR)\n",
    "        mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#             img, mask\n",
    "\n",
    "        img = cv2.resize(img, (params.GetImageSize(), params.GetImageSize()))\n",
    "        mask = cv2.resize(mask, (params.GetImageSize(), params.GetImageSize()))            \n",
    "\n",
    "        height, width = mask.shape\n",
    "        masks = np.zeros((height, width, 4))\n",
    "        for i in range(masks.shape[2]):\n",
    "            masks[:, :, i] = (mask == (i+1))\n",
    "\n",
    "        #moving the channel:\n",
    "        mask_train = np.moveaxis(masks,-1,1)\n",
    "\n",
    "        x_batch += [img]\n",
    "        y_batch.append(mask_train)\n",
    "        r_batch += [mask]\n",
    "\n",
    "    x_batch = np.array(x_batch) / 255.\n",
    "    y_batch = np.array(y_batch) / 255.\n",
    "    r_batch = np.array(r_batch) / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_batch.shape,y_batch.shape,r_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_with_mask(img_name, mask_name):\n",
    "    img = cv2.imread(img_name, cv2.IMREAD_COLOR)\n",
    "    mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "#     img, mask\n",
    "            \n",
    "    img = cv2.resize(img, (params.GetImageSize(), params.GetImageSize()))\n",
    "    mask = cv2.resize(mask, (params.GetImageSize(), params.GetImageSize()))            \n",
    "\n",
    "    height, width = mask.shape\n",
    "    masks = np.zeros((height, width, 4))\n",
    "    for i in range(masks.shape[2]):\n",
    "        masks[:, :, i] = (mask == (i+1))\n",
    "            \n",
    "#     masks = np.moveaxis(masks,-1,1)\n",
    "\n",
    "    return img / 255., masks / 1.\n",
    "\n",
    "def prepare_image_and_mask_for_prediction(img_name, mask_name):\n",
    "    img, masks = read_image_with_mask(img_name, mask_name)\n",
    "    return np.array([img]), np.array([masks])\n",
    "\n",
    "def keras_generator(img_df, mask_df, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            img_name = img_df[index]\n",
    "            mask_name = mask_df[index]\n",
    "            \n",
    "#             print(index, img_name, mask_name)\n",
    "            \n",
    "            index = (index + 1) % len(img_df)\n",
    "            \n",
    "            img, masks = read_image_with_mask(img_name, mask_name)\n",
    "            \n",
    "            x_batch += [img]\n",
    "            y_batch.append(masks)\n",
    "\n",
    "        \n",
    "#         print(x_batch.shape,y_batch.shape)\n",
    "\n",
    "        yield np.array(x_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 6/20 [========>.....................] - ETA: 6:56 - loss: 0.5362 - acc: 0.2878"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aaef5536e5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m               initial_epoch=0)\n\u001b[0m",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/valentin/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "history = model.fit_generator(keras_generator(data.train.image_paths, data.train.masks_paths, batch_size),\n",
    "              steps_per_epoch=20,\n",
    "              epochs=3,\n",
    "              verbose=1,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=keras_generator(data.valid.image_paths, data.valid.masks_paths, batch_size),\n",
    "              validation_steps=5,\n",
    "              class_weight=None,\n",
    "              max_queue_size=10,\n",
    "              workers=1,\n",
    "              use_multiprocessing=False,\n",
    "              shuffle=True,\n",
    "              initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model1 = BuildModel_SegNet()\n",
    "model1.load_weights('unet_best.h5')\n",
    "# model1 = load_model('unet_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# model1 = load_model('segnet_best.h5')\n",
    "model1 = load_model('unet_best.h5', custom_objects={'loss': weighted_categorical_crossentropy(weights)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in keras_generator(data.valid.image_paths, data.valid.masks_paths, 16):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred[:,:,:,2] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassesMap(pred):\n",
    "    res = np.zeros((pred.shape[0], pred.shape[1]), np.uint8)\n",
    "    for r in range(pred.shape[0]):\n",
    "        for c in range(pred.shape[1]):\n",
    "            pred_class_index = np.argmax(pred[r,c,:])\n",
    "            res[r,c] = pred_class_index\n",
    "    res.shape\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 2\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(25, 25))\n",
    "axes[0][0].imshow(x[sample_index])\n",
    "im_0_1 = axes[0][1].imshow(pred[sample_index, ..., 0])\n",
    "im_1_0 = axes[1][0].imshow(pred[sample_index, ..., 1])\n",
    "im_1_1 = axes[1][1].imshow(pred[sample_index, ..., 2])\n",
    "im_2_0 = axes[2][0].imshow(pred[sample_index, ..., 3])\n",
    "# im_2_1 = axes[2][1].imshow(keras.backend.eval(tf.keras.backend.argmax(pred[sample_index], 2)).astype(np.float32))\n",
    "im_2_1 = axes[2][1].imshow(getClassesMap(pred[sample_index]))\n",
    "# im_2_1 = axes[2][1].imshow(pred[sample_index, 20:40, 0:5, 0])\n",
    "im_3_0 = axes[3][0].imshow(y[sample_index, ..., 2])\n",
    "im_3_1 = axes[3][1].imshow(y[sample_index, ..., 1])\n",
    "\n",
    "plt.colorbar(im_0_1, ax=axes[0,1])\n",
    "plt.colorbar(im_1_0, ax=axes[1,0])\n",
    "plt.colorbar(im_1_1, ax=axes[1,1])\n",
    "plt.colorbar(im_2_0, ax=axes[2,0])\n",
    "plt.colorbar(im_2_1, ax=axes[2,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CountErrors(y, pred):\n",
    "    ok_cnt = 0\n",
    "    required = {\n",
    "        0: 0,\n",
    "        1: 0,\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "    }\n",
    "    valid = {\n",
    "        0: [0,0,0,0],\n",
    "        1: [0,0,0,0],\n",
    "        2: [0,0,0,0],\n",
    "        3: [0,0,0,0],\n",
    "    }\n",
    "    errors = {\n",
    "        0: [0,0,0,0],\n",
    "        1: [0,0,0,0],\n",
    "        2: [0,0,0,0],\n",
    "        3: [0,0,0,0],\n",
    "    }\n",
    "    \n",
    "    for r in range(y.shape[0]):\n",
    "        for c in range(y.shape[1]):\n",
    "            pred_class_index = np.argmax(pred[r,c,:])\n",
    "            real_class_index = np.argmax(y[r,c,:])\n",
    "            required[real_class_index] += 1\n",
    "            if pred_class_index not in [0,1,2,3] or real_class_index not in [0,1,2,3]:\n",
    "                print(r,c,pred_class_index, real_class_index)\n",
    "                continue\n",
    "#             print(r,c,pred_class_index, real_class_index)\n",
    "            if pred_class_index == real_class_index:\n",
    "                ok_cnt = ok_cnt + 1\n",
    "                valid[real_class_index][pred_class_index] += 1\n",
    "            else:\n",
    "                errors[real_class_index][pred_class_index] += 1\n",
    "    return ok_cnt, required, valid, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountErrors(y[sample_index], pred[sample_index]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 2\n",
    "\n",
    "ok_cnt, required, valid, errors = CountErrors(y[sample_index], pred[sample_index])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cnt, required, valid, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 5\n",
    "\n",
    "ok_cnt, required, valid, errors = CountErrors(y[sample_index], pred[sample_index])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cnt, required, valid, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image by image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = './validation/sample_4.png'\n",
    "mask_name = './validation/sample_4_mask.png'\n",
    "x,y = prepare_image_and_mask_for_prediction(img_name, mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index in range(4):\n",
    "    img = pred[0, ..., index] / np.max(pred[0, ..., index])\n",
    "    img *= 255.0\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imwrite('unet_{}.png'.format(index), img)\n",
    "    \n",
    "img = getClassesMap(pred[0]).astype(np.float32)\n",
    "img = img / np.max(img)\n",
    "img *= 255.0\n",
    "img = img.astype(np.uint8)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite('unet_classes.png', img)\n",
    "\n",
    "img = y[0].astype(np.float32)\n",
    "img = y[0, ..., 0] * 0.0001 + y[0, ..., 1] * 1 + y[0, ..., 2] * 2 + y[0, ..., 3] * 3\n",
    "img = img / np.max(img)\n",
    "img *= 255.0\n",
    "img = img.astype(np.uint8)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite('unet_gt.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred[0, ..., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[0, ..., 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(getClassesMap(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(sum(getClassesMap(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25, 25))\n",
    "axes[0,0].imshow(x[0])\n",
    "im_0_1 = axes[0][1].imshow(pred[0, ..., 0])\n",
    "\n",
    "plt.colorbar(im_0_1, ax=axes[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred[:,:,:,2] *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cnt, required, valid, errors = CountErrors(y[0], pred[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cnt, required, valid, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate accuracy for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ok_cnt = 0\n",
    "all_required = {\n",
    "    0: 0,\n",
    "    1: 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "}\n",
    "all_valid = {\n",
    "    0: [0,0,0,0],\n",
    "    1: [0,0,0,0],\n",
    "    2: [0,0,0,0],\n",
    "    3: [0,0,0,0],\n",
    "}\n",
    "all_errors = {\n",
    "    0: [0,0,0,0],\n",
    "    1: [0,0,0,0],\n",
    "    2: [0,0,0,0],\n",
    "    3: [0,0,0,0],\n",
    "}\n",
    "\n",
    "for i in tqdm(range(len(data.valid.image_paths))):\n",
    "    img_name = data.valid.image_paths[i]\n",
    "    mask_name = data.valid.masks_paths[i]\n",
    "    \n",
    "    x,y = prepare_image_and_mask_for_prediction(img_name, mask_name)\n",
    "    \n",
    "    pred = model1.predict(x)\n",
    "#     pred[:,:,:,2] *= 2\n",
    "    \n",
    "    ok_cnt, required, valid, errors = CountErrors(y[0], pred[0]) \n",
    "    \n",
    "    all_ok_cnt += ok_cnt\n",
    "    for j in range(4):\n",
    "        all_required[j] = all_required[j] + required[j]\n",
    "        all_valid[j] = [x + y for x, y in zip(all_valid[j], valid[j])]\n",
    "        all_errors[j] = [x + y for x, y in zip(all_errors[j], errors[j])]\n",
    "\n",
    "image_area = params.GetImageSize() * params.GetImageSize()\n",
    "image_cnt = len(data.valid.image_paths)\n",
    "scale = float(image_area * image_cnt) / 100.\n",
    "\n",
    "all_ok_cnt /= scale\n",
    "for j in range(4):\n",
    "    all_required[j] /= scale\n",
    "    all_valid[j] = [x / scale for x in all_valid[j]]\n",
    "    all_errors[j] = [x / scale for x in all_errors[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ok_cnt, all_required, all_valid, all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros([4,4])\n",
    "for x in range(4):\n",
    "    confusion_matrix[x,x] = all_valid[x][x]\n",
    "\n",
    "for real_class in range(4):\n",
    "    for predicted_class in range(4):\n",
    "        if real_class == predicted_class:\n",
    "            continue\n",
    "        confusion_matrix[predicted_class,real_class] = all_errors[real_class][predicted_class]\n",
    "\n",
    "precision = np.zeros([4])\n",
    "for i in range(4):\n",
    "    precision[i] = confusion_matrix[i,i] / sum(confusion_matrix[i,:])\n",
    "    \n",
    "recall = np.zeros([4])\n",
    "for i in range(4):\n",
    "    recall[i] = confusion_matrix[i,i] / sum(confusion_matrix[:,i])\n",
    "        \n",
    "def CalcF(precisionV, recallV):\n",
    "    return 2 * precisionV * recallV / (precisionV + recallV)\n",
    "\n",
    "F = [ CalcF(precisionV, recallV) for precisionV, recallV in zip(precision, recall) ]\n",
    "F = np.array(F)\n",
    "\n",
    "confusion_matrix, precision, recall, F\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(formatter={\"float_kind\": lambda x: \"%0.2f\" % x})\n",
    "\n",
    "print(\"confusion_matrix = \\n{}\".format(confusion_matrix))\n",
    "print(\"precision = {}\".format(precision))\n",
    "print(\"recall = {}\".format(recall))\n",
    "print(\"F = {}\".format(F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
