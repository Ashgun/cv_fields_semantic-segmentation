{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valentin/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, UpSampling2D, Conv2D, MaxPooling2D, Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import params\n",
    "import dataset\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModel():\n",
    "    inp = Input(shape=(params.GetImageSize(), params.GetImageSize(), params.GetChannelsNum()))\n",
    "\n",
    "    conv_1_1 = Conv2D(32, (3, 3), padding='same')(inp)\n",
    "    conv_1_1 = Activation('relu')(conv_1_1)\n",
    "    conv_1_2 = Conv2D(32, (3, 3), padding='same')(conv_1_1)\n",
    "    conv_1_2 = Activation('relu')(conv_1_2)\n",
    "    pool_1 = MaxPooling2D(2)(conv_1_2)\n",
    "\n",
    "    conv_2_1 = Conv2D(64, (3, 3), padding='same')(pool_1)\n",
    "    conv_2_1 = Activation('relu')(conv_2_1)\n",
    "    conv_2_2 = Conv2D(64, (3, 3), padding='same')(conv_2_1)\n",
    "    conv_2_2 = Activation('relu')(conv_2_2)\n",
    "    pool_2 = MaxPooling2D(2)(conv_2_2)\n",
    "\n",
    "    conv_3_1 = Conv2D(128, (3, 3), padding='same')(pool_2)\n",
    "    conv_3_1 = Activation('relu')(conv_3_1)\n",
    "    conv_3_2 = Conv2D(128, (3, 3), padding='same')(conv_3_1)\n",
    "    conv_3_2 = Activation('relu')(conv_3_2)\n",
    "    pool_3 = MaxPooling2D(2)(conv_3_2)\n",
    "\n",
    "    up_1 = UpSampling2D(2, interpolation='bilinear')(pool_3)\n",
    "    conc_1 = Concatenate()([conv_3_2, up_1])\n",
    "    conv_up_1_1 = Conv2D(256, (3, 3), padding='same')(up_1)\n",
    "    conv_up_1_1 = Activation('relu')(conv_up_1_1)\n",
    "    conv_up_1_2 = Conv2D(256, (3, 3), padding='same')(conv_up_1_1)\n",
    "    conv_up_1_2 = Activation('relu')(conv_up_1_2)\n",
    "\n",
    "    up_2 = UpSampling2D(2, interpolation='bilinear')(conv_up_1_2)\n",
    "    conc_2 = Concatenate()([conv_2_2, up_2])\n",
    "    conv_up_2_1 = Conv2D(128, (3, 3), padding='same')(up_2)\n",
    "    conv_up_2_1 = Activation('relu')(conv_up_2_1)\n",
    "    conv_up_2_2 = Conv2D(128, (3, 3), padding='same')(conv_up_2_1)\n",
    "    conv_up_2_2 = Activation('relu')(conv_up_2_2)\n",
    "\n",
    "    up_3 = UpSampling2D(2, interpolation='bilinear')(conv_up_2_2)\n",
    "    conc_3 = Concatenate()([conv_1_2, up_3])\n",
    "    conv_up_3_1 = Conv2D(64, (3, 3), padding='same')(up_3)\n",
    "    conv_up_3_1 = Activation('relu')(conv_up_3_1)\n",
    "    conv_up_3_2 = Conv2D(4, (3, 3), padding='same')(conv_up_3_1)\n",
    "    result = Activation('sigmoid')(conv_up_3_2)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=result)\n",
    "\n",
    "model = BuildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_w = keras.callbacks.ModelCheckpoint('unet_best.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "last_w = keras.callbacks.ModelCheckpoint('unet_last.h5',\n",
    "                                monitor='val_loss',\n",
    "                                verbose=0,\n",
    "                                save_best_only=False,\n",
    "                                save_weights_only=True,\n",
    "                                mode='auto',\n",
    "                                period=1)\n",
    "\n",
    "\n",
    "callbacks = [best_w, last_w]\n",
    "\n",
    "\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "\n",
    "model.compile(adam, 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete reading input data. Will Now print a snippet of it\n",
      "Number of files in Training-set:\t\t200\n",
      "Number of files in Validation-set:\t40\n"
     ]
    }
   ],
   "source": [
    "data = dataset.read_train_validation_big_sets(\n",
    "        train_path = os.path.join(params.training_data_path),\n",
    "        validation_path = os.path.join(params.validation_data_path),\n",
    "        image_size = params.GetImageSize())\n",
    "\n",
    "print(\"Complete reading input data. Will Now print a snippet of it\")\n",
    "print(\"Number of files in Training-set:\\t\\t{}\".format(data.train.num_examples))\n",
    "print(\"Number of files in Validation-set:\\t{}\".format(data.valid.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = data.train.image_paths\n",
    "mask_df = data.train.masks_paths\n",
    "batch_size = 26\n",
    "\n",
    "index = 0\n",
    "while index < 5:\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    r_batch = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img_name = img_df[index]\n",
    "        mask_name = mask_df[index]\n",
    "\n",
    "#             print(index, img_name, mask_name)\n",
    "\n",
    "        index = (index + 1) % len(img_df)\n",
    "\n",
    "        img = cv2.imread(img_name, cv2.IMREAD_COLOR)\n",
    "        mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#             img, mask\n",
    "\n",
    "        img = cv2.resize(img, (params.GetImageSize(), params.GetImageSize()))\n",
    "        mask = cv2.resize(mask, (params.GetImageSize(), params.GetImageSize()))            \n",
    "\n",
    "        height, width = mask.shape\n",
    "        masks = np.zeros((height, width, 4))\n",
    "        for i in range(masks.shape[2]):\n",
    "            masks[:, :, i] = (mask == (i+1))\n",
    "\n",
    "        #moving the channel:\n",
    "        mask_train = np.moveaxis(masks,-1,1)\n",
    "\n",
    "        x_batch += [img]\n",
    "        y_batch.append(mask_train)\n",
    "        r_batch += [mask]\n",
    "\n",
    "    x_batch = np.array(x_batch) / 255.\n",
    "    y_batch = np.array(y_batch) / 255.\n",
    "    r_batch = np.array(r_batch) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, 256, 256, 3), (26, 256, 4, 256), (26, 256, 256))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape,y_batch.shape,r_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_generator(img_df, mask_df, batch_size):\n",
    "    index = 0\n",
    "    while True:\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            img_name = img_df[index]\n",
    "            mask_name = mask_df[index]\n",
    "            \n",
    "#             print(index, img_name, mask_name)\n",
    "            \n",
    "            index = (index + 1) % len(img_df)\n",
    "            \n",
    "            img = cv2.imread(img_name, cv2.IMREAD_COLOR)\n",
    "            mask = cv2.imread(mask_name, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "#             img, mask\n",
    "            \n",
    "            img = cv2.resize(img, (params.GetImageSize(), params.GetImageSize()))\n",
    "            mask = cv2.resize(mask, (params.GetImageSize(), params.GetImageSize()))            \n",
    "            \n",
    "            height, width = mask.shape\n",
    "            masks = np.zeros((height, width, 4))\n",
    "            for i in range(masks.shape[2]):\n",
    "                masks[:, :, i] = (mask == (i+1))\n",
    "            \n",
    "#             masks = np.moveaxis(masks,-1,1)\n",
    "            \n",
    "            x_batch += [img]\n",
    "            y_batch.append(masks)\n",
    "\n",
    "        x_batch = np.array(x_batch) / 255.\n",
    "        y_batch = np.array(y_batch) / 1.\n",
    "        \n",
    "#         print(x_batch.shape,y_batch.shape)\n",
    "\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 10/100 [==>...........................] - ETA: 36:38 - loss: 1.3577"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model.fit_generator(keras_generator(data.train.image_paths, data.train.masks_paths, batch_size),\n",
    "              steps_per_epoch=100,\n",
    "              epochs=3,\n",
    "              verbose=1,\n",
    "              callbacks=callbacks,\n",
    "              validation_data=keras_generator(data.valid.image_paths, data.valid.masks_paths, batch_size),\n",
    "              validation_steps=50,\n",
    "              class_weight=None,\n",
    "              max_queue_size=10,\n",
    "              workers=1,\n",
    "              use_multiprocessing=True,\n",
    "              shuffle=True,\n",
    "              initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model1 = BuildModel()\n",
    "model1.load_weights('unet_best.h5')\n",
    "# model1 = load_model('unet_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in keras_generator(data.valid.image_paths, data.valid.masks_paths, 16):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "keras.backend.eval(tf.keras.backend.argmax(pred[sample_index], 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassesMap(pred):\n",
    "    res = np.zeros((pred.shape[0], pred.shape[1]), np.uint8)\n",
    "    for r in range(pred.shape[0]):\n",
    "        for c in range(pred.shape[1]):\n",
    "            pred_class_index = np.argmax(pred[r,c,:])\n",
    "            res[r,c] = pred_class_index\n",
    "    res.shape\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getClassesMap(pred[sample_index]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 1\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(25, 25))\n",
    "axes[0][0].imshow(x[sample_index])\n",
    "im_0_1 = axes[0][1].imshow(pred[sample_index, ..., 0])\n",
    "im_1_0 = axes[1][0].imshow(pred[sample_index, ..., 1])\n",
    "im_1_1 = axes[1][1].imshow(pred[sample_index, ..., 2])\n",
    "im_2_0 = axes[2][0].imshow(pred[sample_index, ..., 3])\n",
    "# im_2_1 = axes[2][1].imshow(keras.backend.eval(tf.keras.backend.argmax(pred[sample_index], 2)).astype(np.float32))\n",
    "# im_2_1 = axes[2][1].imshow(getClassesMap(pred[sample_index]))\n",
    "im_2_1 = axes[2][1].imshow(pred[sample_index, 20:40, 0:5, 0])\n",
    "\n",
    "plt.colorbar(im_0_1, ax=axes[0,1])\n",
    "plt.colorbar(im_1_0, ax=axes[1,0])\n",
    "plt.colorbar(im_1_1, ax=axes[1,1])\n",
    "plt.colorbar(im_2_0, ax=axes[2,0])\n",
    "plt.colorbar(im_2_1, ax=axes[2,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(pred[sample_index, 20:40, 0:5, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[sample_index][15,110,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(pred[sample_index][15,110,:])/sum(np.exp(pred[sample_index][15,110,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pred[sample_index][15,110,:]\n",
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.eval(tf.keras.backend.argmax(pred[sample_index], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[sample_index][:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.eval(tf.keras.backend.argmax(pred[sample_index], 2)) == (y[sample_index][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 1\n",
    "\n",
    "ok_cnt = 0\n",
    "errors = {\n",
    "    0: [0,0,0,0],\n",
    "    1: [0,0,0,0],\n",
    "    2: [0,0,0,0],\n",
    "    3: [0,0,0,0],\n",
    "}\n",
    "for r in range(y[sample_index].shape[0]):\n",
    "    for c in range(y[sample_index].shape[1]):\n",
    "        pred_class_index = np.argmax(pred[sample_index][r,c,:]) + 0\n",
    "        real_class_index = np.argmax(y[sample_index][r,c,:])\n",
    "#         print(r,c,pred_class_index, real_class_index)\n",
    "        if pred_class_index == real_class_index:\n",
    "            ok_cnt = ok_cnt + 1\n",
    "        else:\n",
    "            errors[real_class_index][pred_class_index] = errors[real_class_index][pred_class_index] + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cnt,errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
